# main.py
# ì´ë¯¸ì§€ ë¶„ë¥˜ - 5-Fold ì•™ìƒë¸” + ì œì¶œ íŒŒì¼ ìƒì„± (íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨)

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import timm
import albumentations as A
from albumentations.pytorch import ToTensorV2
import cv2
import numpy as np
import pandas as pd
from tqdm import tqdm
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import f1_score
import os
from datetime import datetime

# ========== ì„¤ì • ==========
IMG_SIZE = 380
BATCH_SIZE = 16
EPOCHS = 50
LR = 0.0003
N_FOLDS = 5
DEVICE = 'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'

# íƒ€ì„ìŠ¤íƒ¬í”„ ìƒì„± (í”„ë¡œê·¸ë¨ ì‹œì‘ ì‹œ í•œ ë²ˆë§Œ)
TIMESTAMP = datetime.now().strftime('%Y%m%d_%H%M%S')
print(f'Timestamp: {TIMESTAMP}')
print(f'Using device: {DEVICE}')

# ========== ë°ì´í„°ì…‹ ==========
class MyDataset(Dataset):
    def __init__(self, df, transform, is_test=False):
        self.df = df.reset_index(drop=True)
        self.transform = transform
        self.is_test = is_test
        
    def __len__(self):
        return len(self.df)
    
    def __getitem__(self, idx):
        row = self.df.iloc[idx]
        
        # ì´ë¯¸ì§€ ë¡œë“œ
        image = cv2.imread(row['image_path'])
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        # ì¦ê°• ì ìš©
        image = self.transform(image=image)['image']
        
        if self.is_test:
            return image
        else:
            label = row['label']
            return image, label

# ========== ì¦ê°• ==========
train_transform = A.Compose([
    A.Resize(IMG_SIZE, IMG_SIZE),
    A.HorizontalFlip(p=0.5),
    A.VerticalFlip(p=0.3),
    A.Rotate(limit=15, p=0.5),
    A.RandomBrightnessContrast(p=0.5),
    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ToTensorV2(),
])

val_transform = A.Compose([
    A.Resize(IMG_SIZE, IMG_SIZE),
    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ToTensorV2(),
])

# ========== í•™ìŠµ í•¨ìˆ˜ ==========
def train_epoch(model, loader, criterion, optimizer, scheduler):
    model.train()
    losses = []
    
    for images, labels in tqdm(loader, desc='Train'):
        images = images.to(DEVICE)
        labels = labels.to(DEVICE)
        
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        scheduler.step()
        
        losses.append(loss.item())
    
    return np.mean(losses)

def validate(model, loader):
    model.eval()
    preds_list = []
    labels_list = []
    
    with torch.no_grad():
        for images, labels in tqdm(loader, desc='Val'):
            images = images.to(DEVICE)
            outputs = model(images)
            preds = outputs.argmax(dim=1)
            
            preds_list.extend(preds.cpu().numpy())
            labels_list.extend(labels.numpy())
    
    f1 = f1_score(labels_list, preds_list, average='macro')
    return f1

# ========== í´ë“œ í•™ìŠµ ==========
def train_fold(fold, train_df, val_df):
    print(f'\n{"="*50}')
    print(f'Fold {fold} í•™ìŠµ ì‹œì‘')
    print(f'{"="*50}')
    
    # ë°ì´í„° ë¡œë”
    train_dataset = MyDataset(train_df, train_transform)
    val_dataset = MyDataset(val_df, val_transform)
    
    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)
    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)
    
    # ëª¨ë¸
    model = timm.create_model('tf_efficientnetv2_m', pretrained=True, num_classes=17)
    model = model.to(DEVICE)
    
    # ì˜µí‹°ë§ˆì´ì € & ìŠ¤ì¼€ì¤„ëŸ¬
    optimizer = optim.AdamW(model.parameters(), lr=LR, weight_decay=0.01)
    scheduler = optim.lr_scheduler.OneCycleLR(
        optimizer,
        max_lr=LR,
        epochs=EPOCHS,
        steps_per_epoch=len(train_loader)
    )
    criterion = nn.CrossEntropyLoss()
    
    # í•™ìŠµ ë£¨í”„
    best_f1 = 0
    patience_counter = 0
    patience = 10
    
    for epoch in range(EPOCHS):
        train_loss = train_epoch(model, train_loader, criterion, optimizer, scheduler)
        val_f1 = validate(model, val_loader)
        
        print(f'Epoch {epoch+1}/{EPOCHS} - Loss: {train_loss:.4f}, F1: {val_f1:.4f}')
        
        # ë² ìŠ¤íŠ¸ ëª¨ë¸ ì €ì¥
        if val_f1 > best_f1:
            best_f1 = val_f1
            patience_counter = 0
            
            os.makedirs('models', exist_ok=True)
            # íŒŒì¼ëª…: fold{N}_{timestamp}_f1{score}.pth
            model_filename = f'models/fold{fold}_{TIMESTAMP}_f1{best_f1:.4f}.pth'
            torch.save(model.state_dict(), model_filename)
            print(f'âœ… Best F1: {best_f1:.4f} - ì €ì¥: {model_filename}')
        else:
            patience_counter += 1
            print(f'â³ Patience: {patience_counter}/{patience}')
        
        # Early Stopping
        if patience_counter >= patience:
            print(f'Early stopping at epoch {epoch+1}')
            break
    
    print(f'\nFold {fold} ì™„ë£Œ - Best F1: {best_f1:.4f}')
    return best_f1

# ========== TTA ì˜ˆì¸¡ ==========
def predict_with_tta(model, image):
    """TTAë¥¼ ì‚¬ìš©í•œ ì˜ˆì¸¡"""
    model.eval()
    predictions = []
    
    with torch.no_grad():
        # Original
        pred = model(image)
        predictions.append(pred)
        
        # Horizontal Flip
        pred = model(torch.flip(image, dims=[3]))
        predictions.append(pred)
        
        # Vertical Flip
        pred = model(torch.flip(image, dims=[2]))
        predictions.append(pred)
        
        # Both Flips
        pred = model(torch.flip(image, dims=[2, 3]))
        predictions.append(pred)
    
    # Average
    final_pred = torch.stack(predictions).mean(dim=0)
    return final_pred

# ========== ì•™ìƒë¸” ì¶”ë¡  ==========
def inference_ensemble(test_df, fold_info, use_tta=True):
    """ì—¬ëŸ¬ í´ë“œ ëª¨ë¸ë¡œ ì•™ìƒë¸” ì¶”ë¡ 
    
    Args:
        test_df: í…ŒìŠ¤íŠ¸ ë°ì´í„°í”„ë ˆì„
        fold_info: [(foldë²ˆí˜¸, f1ì ìˆ˜, íŒŒì¼ê²½ë¡œ), ...] ë¦¬ìŠ¤íŠ¸
        use_tta: TTA ì‚¬ìš© ì—¬ë¶€
    """
    print(f'\n{"="*50}')
    print(f'ì¶”ë¡  ì‹œì‘')
    print(f'ëª¨ë¸ ê°œìˆ˜: {len(fold_info)}')
    print(f'TTA: {use_tta}')
    print(f'{"="*50}')
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹
    test_dataset = MyDataset(test_df, val_transform, is_test=True)
    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=4)
    
    # ëª¨ë¸ ë¡œë“œ
    models = []
    avg_f1 = 0
    for fold, f1, model_path in fold_info:
        model = timm.create_model('tf_efficientnetv2_m', pretrained=False, num_classes=17)
        model.load_state_dict(torch.load(model_path))
        model = model.to(DEVICE)
        model.eval()
        models.append(model)
        avg_f1 += f1
        print(f'âœ… Fold {fold} (F1: {f1:.4f}) ë¡œë“œ')
    
    avg_f1 /= len(fold_info)
    
    # ì¶”ë¡ 
    all_predictions = []
    
    for images in tqdm(test_loader, desc='Inference'):
        images = images.to(DEVICE)
        
        fold_preds = []
        for model in models:
            if use_tta:
                pred = predict_with_tta(model, images)
            else:
                with torch.no_grad():
                    pred = model(images)
            
            fold_preds.append(pred.cpu())
        
        # í´ë“œ ì•™ìƒë¸” (í‰ê· )
        ensemble_pred = torch.stack(fold_preds).mean(dim=0)
        final_class = ensemble_pred.argmax(dim=1).item()
        all_predictions.append(final_class)
    
    return all_predictions, avg_f1

# ========== ì œì¶œ íŒŒì¼ ìƒì„± ==========
def create_submission(test_df, predictions, avg_f1, filename_prefix='submission'):
    """ì œì¶œ íŒŒì¼ ìƒì„± (ë‚ ì§œ_ì‹œê°„_f1score í¬í•¨)"""
    
    # íŒŒì¼ëª…: submission_{timestamp}_f1{score}.csv
    filename = f'{filename_prefix}_{TIMESTAMP}_f1{avg_f1:.4f}.csv'
    
    submission = pd.DataFrame({
        'id': test_df['id'],
        'label': predictions
    })
    
    submission.to_csv(filename, index=False)
    
    print(f'\n{"="*50}')
    print(f'ì œì¶œ íŒŒì¼ ìƒì„±: {filename}')
    print(f'{"="*50}')
    print(submission.head(10))
    print(f'\nì˜ˆì¸¡ ë¶„í¬:')
    print(submission['label'].value_counts().sort_index())
    print(f'\nâœ… ì œì¶œ íŒŒì¼ ì €ì¥ ì™„ë£Œ!')
    
    return filename

# ========== ë©”ì¸ ì‹¤í–‰ ==========
if __name__ == '__main__':
    print('='*50)
    print('ì´ë¯¸ì§€ ë¶„ë¥˜ í•™ìŠµ & ì¶”ë¡ ')
    print('='*50)
    
    # ===== 1. í•™ìŠµ ë°ì´í„° ë¡œë“œ =====
    train_df = pd.read_csv('data/train.csv')
    
    print(f'í•™ìŠµ ë°ì´í„°: {len(train_df)}ì¥')
    print(f'í´ë˜ìŠ¤: {train_df["label"].nunique()}ê°œ')
    
    # ===== 2. K-Fold í•™ìŠµ =====
    skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=42)
    fold_results = []
    
    for fold, (train_idx, val_idx) in enumerate(skf.split(train_df, train_df['label'])):
        train_fold_df = train_df.iloc[train_idx]
        val_fold_df = train_df.iloc[val_idx]
        
        best_f1 = train_fold(fold, train_fold_df, val_fold_df)
        
        # ì €ì¥ëœ ëª¨ë¸ íŒŒì¼ ê²½ë¡œ ì°¾ê¸°
        model_path = f'models/fold{fold}_{TIMESTAMP}_f1{best_f1:.4f}.pth'
        
        fold_results.append({
            'fold': fold,
            'f1': best_f1,
            'model_path': model_path
        })
    
    # ê²°ê³¼ ì¶œë ¥ ë° ì €ì¥
    results_df = pd.DataFrame(fold_results)
    print(f'\n{"="*50}')
    print('í•™ìŠµ ê²°ê³¼')
    print(f'{"="*50}')
    print(results_df[['fold', 'f1']])
    print(f'\ní‰ê·  F1: {results_df["f1"].mean():.4f}')
    print(f'ìµœê³  F1: {results_df["f1"].max():.4f}')
    
    # ê²°ê³¼ CSV ì €ì¥ (íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨)
    results_filename = f'models/fold_results_{TIMESTAMP}_avgf1{results_df["f1"].mean():.4f}.csv'
    results_df.to_csv(results_filename, index=False)
    print(f'\nê²°ê³¼ ì €ì¥: {results_filename}')
    
    # ===== 3. í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ =====
    test_df = pd.read_csv('data/test.csv')
    
    # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ê²½ë¡œ (í•„ìš”ì‹œ ìˆ˜ì •)
    # test_df['image_path'] = test_df['id'].apply(lambda x: f'data/test/{x}.jpg')
    
    print(f'\ní…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(test_df)}ì¥')
    
    # ===== 4. ìƒìœ„ 4ê°œ í´ë“œ ì„ íƒ =====
    results_df_sorted = results_df.sort_values('f1', ascending=False)
    best_4_folds = results_df_sorted.head(4)
    
    fold_info = [
        (row['fold'], row['f1'], row['model_path'])
        for _, row in best_4_folds.iterrows()
    ]
    
    print(f'\nì„ íƒëœ í´ë“œ: {[f[0] for f in fold_info]}')
    
    # ===== 5. ì•™ìƒë¸” ì¶”ë¡  =====
    predictions, avg_f1 = inference_ensemble(test_df, fold_info=fold_info, use_tta=True)
    
    # ===== 6. ì œì¶œ íŒŒì¼ ìƒì„± =====
    submission_filename = create_submission(test_df, predictions, avg_f1, filename_prefix='submission')
    
    print(f'\n{"="*50}')
    print('ìƒì„±ëœ íŒŒì¼ë“¤')
    print(f'{"="*50}')
    print(f'ğŸ“ ëª¨ë¸ íŒŒì¼:')
    for fold, f1, path in fold_info:
        print(f'  - {path}')
    print(f'\nğŸ“ ê²°ê³¼ íŒŒì¼: {results_filename}')
    print(f'ğŸ“ ì œì¶œ íŒŒì¼: {submission_filename}')
    
    print('\nâœ… ëª¨ë“  ì‘ì—… ì™„ë£Œ!')
```

---

## ìƒì„±ë˜ëŠ” íŒŒì¼ëª… ì˜ˆì‹œ
```
models/
â”œâ”€â”€ fold0_20241102_143025_f10.9423.pth
â”œâ”€â”€ fold1_20241102_143025_f10.9512.pth
â”œâ”€â”€ fold2_20241102_143025_f10.9387.pth
â”œâ”€â”€ fold3_20241102_143025_f10.9456.pth
â”œâ”€â”€ fold4_20241102_143025_f10.9401.pth
â””â”€â”€ fold_results_20241102_143025_avgf10.9436.csv

submission_20241102_143025_f10.9450.csv
```

**íŒŒì¼ëª… êµ¬ì¡°:**
```
fold{N}_{ë‚ ì§œ}_{ì‹œê°„}_f1{ì ìˆ˜}.pth
fold_results_{ë‚ ì§œ}_{ì‹œê°„}_avgf1{í‰ê· ì ìˆ˜}.csv
submission_{ë‚ ì§œ}_{ì‹œê°„}_f1{ì•™ìƒë¸”ì ìˆ˜}.csv